Input text:
"John enjoys playing football while Mary loves reading books in the library."
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)
nltk.download('wordnet', quiet=True)
text = "John enjoys playing football while Mary loves reading books in the library."
tokens = word_tokenize(text)
print("Tokens:", tokens)
stop_words = set(stopwords.words('english'))
filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]
print("\nAfter removing stopwords:", filtered_tokens)
lemmatizer = WordNetLemmatizer()
def get_wordnet_pos(tag):
    if tag.startswith('J'):
        return wordnet.ADJ
    elif tag.startswith('V'):
        return wordnet.VERB
    elif tag.startswith('N'):
        return wordnet.NOUN
    elif tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN
pos_tags = pos_tag(filtered_tokens)
lemmas = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]
print("\nLemmatized words:", lemmas)
verbs_nouns = [lemmatizer.lemmatize(word, get_wordnet_pos(pos))
for word, pos in pos_tags if pos.startswith('N') or pos.startswith('V')]

print("\nOnly Verbs and Nouns:", verbs_nouns)
